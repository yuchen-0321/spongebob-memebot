# GTX 1660 Super æ·±åº¦å­¸ç¿’ç’°å¢ƒé…ç½®å®Œæ•´æŒ‡å—

> **é©ç”¨ç¯„åœ**: NVIDIA GTX 1660 Super 6GB VRAM æ·±åº¦å­¸ç¿’é–‹ç™¼ç’°å¢ƒ  
> **æ›´æ–°æ—¥æœŸ**: 2025å¹´6æœˆ  
> **æŠ€è¡“æ£§**: CUDA 12.6, TensorFlow-GPU 2.10.1, Python 3.10

---

## ğŸ“‹ ç›®éŒ„

1. [GTX 1660 Super ç’°å¢ƒé…ç½®æŒ‡å—](#1-gtx-1660-super-ç’°å¢ƒé…ç½®æŒ‡å—)
2. [æ·±åº¦å­¸ç¿’é–‹ç™¼ç’°å¢ƒ](#2-æ·±åº¦å­¸ç¿’é–‹ç™¼ç’°å¢ƒ)
3. [é€šç”¨åŸ·è¡ŒæŒ‡ä»¤é›†](#3-é€šç”¨åŸ·è¡ŒæŒ‡ä»¤é›†)
4. [æ–° Claude å”ä½œæŒ‡å—](#4-æ–°-claude-å”ä½œæŒ‡å—)
5. [æ•…éšœæ’é™¤æŒ‡å—](#5-æ•…éšœæ’é™¤æŒ‡å—)
6. [æª”æ¡ˆç®¡ç†å»ºè­°](#6-æª”æ¡ˆç®¡ç†å»ºè­°)

---

## 1. GTX 1660 Super ç’°å¢ƒé…ç½®æŒ‡å—

### ğŸ” ç¡¬é«”è¦æ ¼ç¢ºèª

**NVIDIA GeForce GTX 1660 Super è¦æ ¼**:
- **VRAM**: 6GB GDDR6
- **CUDA Cores**: 1408
- **è¨ˆç®—èƒ½åŠ›**: 7.5 (Turing æ¶æ§‹)
- **å¯ç”¨ VRAM**: ç´„ 4-4.5GB (æ‰£é™¤ç³»çµ±ä½”ç”¨)
- **æ¨è–¦æ‰¹æ¬¡å¤§å°**: 32-64
- **æ”¯æ´ç‰¹æ€§**: æ··åˆç²¾åº¦è¨“ç·´ã€ç¾ä»£æ·±åº¦å­¸ç¿’æ¡†æ¶

### ğŸš— NVIDIA é©…å‹•å®‰è£

#### é©—è­‰ç•¶å‰é©…å‹•
```bash
nvidia-smi
```

**æœŸæœ›è¼¸å‡ºç¯„ä¾‹**:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 560.94    Driver Version: 560.94    CUDA Version: 12.6        |
+-----------------------------------------------------------------------------+
| GPU  Name             Driver-Model | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce GTX 1660... |   00000000:01:00.0 On |                  N/A |
| 43%   46C    P0    35W / 125W |   1541MiB /  6144MiB |      1%      Default |
+-----------------------------------------------------------------------------+
```

#### é©…å‹•æ›´æ–°æ­¥é©Ÿ
1. **ä¸‹è¼‰æœ€æ–°é©…å‹•**: [NVIDIA å®˜æ–¹é©…å‹•é é¢](https://www.nvidia.com/drivers/)
2. **é¸æ“‡é…ç½®**: GeForce GTX 1660 Super, Windows 11, 64-bit
3. **æ¸…ç†å®‰è£**: ä½¿ç”¨ DDU (Display Driver Uninstaller) æ¸…ç†èˆŠé©…å‹•
4. **é‡æ–°å®‰è£**: åŸ·è¡Œä¸‹è¼‰çš„é©…å‹•å®‰è£ç¨‹å¼

### ğŸ› ï¸ CUDA Toolkit å®‰è£

#### æ¨è–¦ç‰ˆæœ¬é¸æ“‡
- **CUDA 11.8**: èˆ‡ TensorFlow 2.10-2.13 æœ€ç›¸å®¹
- **CUDA 12.x**: æ”¯æ´æœ€æ–°ç‰¹æ€§ï¼Œä½†ç›¸å®¹æ€§éœ€æ³¨æ„

#### å®‰è£æ­¥é©Ÿ (CUDA 11.8)
1. **ä¸‹è¼‰ CUDA 11.8**: [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-11-8-0-download-archive)
2. **é¸æ“‡ç‰ˆæœ¬**: Windows â†’ x86_64 â†’ 11 â†’ exe (local)
3. **åŸ·è¡Œå®‰è£**: é¸æ“‡è‡ªè¨‚å®‰è£ï¼Œå–æ¶ˆ Visual Studio Integration
4. **ç’°å¢ƒè®Šæ•¸ç¢ºèª**:
   ```
   CUDA_PATH = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
   PATH åŒ…å«: %CUDA_PATH%\bin
   ```

#### é©—è­‰å®‰è£
```bash
nvcc --version
```

**æœŸæœ›è¼¸å‡º**:
```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022
Cuda compilation tools, release 11.8, V11.8.89
```

### ğŸ“¦ cuDNN é…ç½®

#### ä¸‹è¼‰èˆ‡å®‰è£
1. **è¨»å†Š NVIDIA Developer**: [cuDNN ä¸‹è¼‰é é¢](https://developer.nvidia.com/cudnn)
2. **é¸æ“‡ç‰ˆæœ¬**: cuDNN v8.6.0 for CUDA 11.8
3. **è§£å£“é…ç½®**:
   ```
   ä¸‹è¼‰: cudnn-windows-x86_64-8.6.0.163_cuda11-archive.zip
   è§£å£“åˆ°: C:\tools\cuda\
   ```
4. **ç’°å¢ƒè®Šæ•¸æ·»åŠ **:
   ```
   PATH æ·»åŠ : C:\tools\cuda\bin
   ```

### âœ… å®‰è£é©—è­‰

#### å®Œæ•´é©—è­‰è…³æœ¬
å»ºç«‹ `gpu_test.py`:
```python
import tensorflow as tf

print("="*50)
print("ğŸ” GPU ç’°å¢ƒé©—è­‰")
print("="*50)

# åŸºæœ¬è³‡è¨Š
print(f"TensorFlow ç‰ˆæœ¬: {tf.__version__}")
print(f"CUDA æ”¯æ´: {tf.test.is_built_with_cuda()}")

# GPU æª¢æ¸¬
gpus = tf.config.list_physical_devices('GPU')
print(f"åµæ¸¬åˆ° GPU: {len(gpus)} å€‹")

if gpus:
    print("âœ… GPU è³‡è¨Š:")
    for gpu in gpus:
        print(f"   {gpu}")
        
    # è¨­å®šè¨˜æ†¶é«”å¢é•·
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)
    
    # æ¸¬è©¦è¨ˆç®—
    print("\nğŸ§® GPU è¨ˆç®—æ¸¬è©¦...")
    with tf.device('/GPU:0'):
        a = tf.random.normal([2000, 2000])
        b = tf.random.normal([2000, 2000])
        c = tf.matmul(a, b)
    print("âœ… GTX 1660 Super é‹è¡Œæ­£å¸¸ï¼")
    
else:
    print("âŒ æ²’æœ‰åµæ¸¬åˆ° GPU")
```

åŸ·è¡Œæ¸¬è©¦:
```bash
python gpu_test.py
```

### ğŸ”§ å¸¸è¦‹å•é¡Œè§£æ±º

#### å•é¡Œ 1: GPU ä¸è¢«åµæ¸¬
**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# æª¢æŸ¥é©…å‹•
nvidia-smi

# é‡æ–°å®‰è£ TensorFlow GPU ç‰ˆæœ¬
pip uninstall tensorflow
pip install tensorflow-gpu==2.10.1
```

#### å•é¡Œ 2: CUDA ç‰ˆæœ¬è¡çª
**è§£æ±ºæ–¹æ¡ˆ**:
- ç¢ºèª TensorFlow ç‰ˆæœ¬èˆ‡ CUDA ç‰ˆæœ¬ç›¸å®¹æ€§
- ä½¿ç”¨ `conda install tensorflow-gpu` è‡ªå‹•è™•ç†ä¾è³´

#### å•é¡Œ 3: è¨˜æ†¶é«”ä¸è¶³
**è§£æ±ºæ–¹æ¡ˆ**:
```python
# è¨­å®šè¨˜æ†¶é«”é€æ¼¸å¢é•·
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)
```

---

## 2. æ·±åº¦å­¸ç¿’é–‹ç™¼ç’°å¢ƒ

### ğŸ Python ç’°å¢ƒç®¡ç†

#### Anaconda å®‰è£èˆ‡é…ç½®
```bash
# ä¸‹è¼‰ Anaconda
# https://www.anaconda.com/products/distribution

# å‰µå»ºå°ˆç”¨ç’°å¢ƒ
conda create --name deeplearning python=3.10 -y
conda activate deeplearning

# é©—è­‰ç’°å¢ƒ
python --version
which python
```

#### è™›æ“¬ç’°å¢ƒæœ€ä½³å¯¦è¸
```bash
# å°ˆæ¡ˆç‰¹å®šç’°å¢ƒ
conda create --name project_name python=3.10 -y

# ç’°å¢ƒåŒ¯å‡ºèˆ‡é‡ç¾
conda env export > environment.yml
conda env create -f environment.yml
```

### ğŸ“š å¥—ä»¶å®‰è£æ¸…å–®

#### æ ¸å¿ƒæ·±åº¦å­¸ç¿’å¥—ä»¶
```bash
# TensorFlow GPU ç‰ˆæœ¬
pip install tensorflow-gpu==2.10.1

# PyTorch GPU ç‰ˆæœ¬ (æ›¿ä»£é¸æ“‡)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# åŸºç¤ç§‘å­¸è¨ˆç®—
pip install numpy==1.24.3 pandas==2.0.3 scipy==1.10.1
```

#### æ©Ÿå™¨å­¸ç¿’èˆ‡è³‡æ–™è™•ç†
```bash
pip install scikit-learn==1.3.0
pip install matplotlib==3.7.2 seaborn==0.12.2
pip install pillow opencv-python
pip install tqdm jupyterlab
```

#### å°ˆæ¥­ NLP å¥—ä»¶
```bash
pip install transformers datasets tokenizers
pip install nltk spacy jieba  # ä¸­æ–‡è™•ç†
pip install sentence-transformers  # è©åµŒå…¥
```

#### é›»è…¦è¦–è¦ºå¥—ä»¶
```bash
pip install opencv-python albumentations
pip install timm  # PyTorch å½±åƒæ¨¡å‹
pip install torchvision
```

#### é–‹ç™¼èˆ‡ç›£æ§å·¥å…·
```bash
pip install tensorboard wandb  # å¯¦é©—è¿½è¹¤
pip install pytest black flake8  # ä»£ç¢¼å“è³ª
pip install ipywidgets notebook  # Jupyter æ“´å±•
```

### ğŸ® GPU è¨˜æ†¶é«”è¨­å®š

#### TensorFlow è¨˜æ†¶é«”ç®¡ç†
```python
import tensorflow as tf

# è¨˜æ†¶é«”é€æ¼¸å¢é•·è¨­å®š (é‡è¦!)
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("âœ… GPU è¨˜æ†¶é«”è¨­å®šå®Œæˆ")
    except RuntimeError as e:
        print(f"è¨˜æ†¶é«”è¨­å®šéŒ¯èª¤: {e}")

# é™åˆ¶è¨˜æ†¶é«”ä½¿ç”¨ (å¯é¸)
if gpus:
    tf.config.set_memory_growth(gpus[0], True)
    tf.config.experimental.set_virtual_device_configuration(
        gpus[0],
        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]
    )
```

#### PyTorch è¨˜æ†¶é«”ç®¡ç†
```python
import torch

# æª¢æŸ¥ CUDA å¯ç”¨æ€§
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
print(f"GPU æ•¸é‡: {torch.cuda.device_count()}")
print(f"GPU åç¨±: {torch.cuda.get_device_name(0)}")

# è¨˜æ†¶é«”ç®¡ç†
torch.cuda.empty_cache()  # æ¸…ç†å¿«å–
torch.backends.cudnn.benchmark = True  # å„ªåŒ– cuDNN
```

### ğŸ“Š æ•ˆèƒ½ç›£æ§

#### å³æ™‚ GPU ç›£æ§
```bash
# åŸºæœ¬ç›£æ§
nvidia-smi -l 1

# è©³ç´°ç›£æ§
watch -n 1 'nvidia-smi --query-gpu=timestamp,name,temperature.gpu,utilization.gpu,memory.used,memory.total --format=csv'

# èˆ‡å…¶ä»–æŒ‡ä»¤çµåˆ
htop &  # CPU ç›£æ§
nvidia-smi -l 1  # GPU ç›£æ§
```

#### Python è…³æœ¬ç›£æ§
```python
import GPUtil
import time

def monitor_gpu():
    while True:
        gpus = GPUtil.getGPUs()
        for gpu in gpus:
            print(f"GPU {gpu.id}: {gpu.name}")
            print(f"  æº«åº¦: {gpu.temperature}Â°C")
            print(f"  ä½¿ç”¨ç‡: {gpu.load*100:.1f}%")
            print(f"  è¨˜æ†¶é«”: {gpu.memoryUsed}MB / {gpu.memoryTotal}MB")
        time.sleep(1)

# å®‰è£: pip install gputil
# åŸ·è¡Œ: monitor_gpu()
```

### ğŸ”„ ç‰ˆæœ¬ç®¡ç†

#### å¥—ä»¶ç‰ˆæœ¬å›ºå®š
```bash
# ç”Ÿæˆ requirements.txt
pip freeze > requirements.txt

# å®‰è£æŒ‡å®šç‰ˆæœ¬
pip install -r requirements.txt

# Conda ç’°å¢ƒåŒ¯å‡º
conda env export --no-builds > environment.yml
```

#### ç‰ˆæœ¬ç›¸å®¹æ€§è¡¨æ ¼

| TensorFlow | Python | CUDA | cuDNN | æ¨è–¦ç”¨é€” |
|------------|--------|------|-------|----------|
| 2.10.1     | 3.8-3.11 | 11.2 | 8.1   | ç©©å®šç”Ÿç”¢ |
| 2.13.0     | 3.8-3.11 | 11.8 | 8.6   | å¹³è¡¡é¸æ“‡ |
| 2.15.0     | 3.9-3.12 | 12.2 | 8.9   | æœ€æ–°ç‰¹æ€§ |

---

## 3. é€šç”¨åŸ·è¡ŒæŒ‡ä»¤é›†

### ğŸ” ç’°å¢ƒæª¢æŸ¥æŒ‡ä»¤

#### GPU ç‹€æ…‹æª¢æŸ¥
```bash
# åŸºæœ¬ GPU è³‡è¨Š
nvidia-smi

# è©³ç´° GPU è³‡è¨Š
nvidia-smi -q

# GPU ç¨‹åºæ¸…å–®
nvidia-smi pmon

# CUDA ç‰ˆæœ¬
nvcc --version
cat /usr/local/cuda/version.txt  # Linux
```

#### Python ç’°å¢ƒæª¢æŸ¥
```bash
# Python ç‰ˆæœ¬èˆ‡è·¯å¾‘
python --version
which python

# å¥—ä»¶ç‰ˆæœ¬æª¢æŸ¥
python -c "import tensorflow as tf; print(f'TensorFlow: {tf.__version__}')"
python -c "import torch; print(f'PyTorch: {torch.__version__}')"

# GPU å¯ç”¨æ€§æª¢æŸ¥
python -c "import tensorflow as tf; print('GPUå¯ç”¨:', len(tf.config.list_physical_devices('GPU')) > 0)"
python -c "import torch; print('CUDAå¯ç”¨:', torch.cuda.is_available())"
```

#### å¥—ä»¶åˆ—è¡¨èˆ‡æœç´¢
```bash
# å·²å®‰è£å¥—ä»¶
pip list
conda list

# æœç´¢ç‰¹å®šå¥—ä»¶
pip list | grep tensorflow
conda list | grep torch

# æª¢æŸ¥éæœŸå¥—ä»¶
pip list --outdated
```

### ğŸ“Š å³æ™‚ç›£æ§æŒ‡ä»¤

#### GPU æ•ˆèƒ½ç›£æ§
```bash
# æ¯ç§’æ›´æ–° GPU ç‹€æ…‹
nvidia-smi -l 1

# è‡ªè¨‚ç›£æ§æ ¼å¼
nvidia-smi --query-gpu=timestamp,name,temperature.gpu,utilization.gpu,memory.used,memory.total --format=csv -l 1

# ç›£æ§ç‰¹å®š GPU
nvidia-smi -i 0 -l 1

# çµåˆ watch æŒ‡ä»¤
watch -n 1 nvidia-smi
```

#### ç³»çµ±è³‡æºç›£æ§
```bash
# CPU èˆ‡è¨˜æ†¶é«”
htop
top

# ç£ç¢Ÿä½¿ç”¨
df -h
du -sh *

# ç¶²è·¯ç›£æ§
iftop
```

#### ç›£æ§è…³æœ¬çµ„åˆ
```bash
# å»ºç«‹ monitor.sh
#!/bin/bash
echo "é–‹å§‹ç³»çµ±ç›£æ§..."
trap 'kill $(jobs -p)' EXIT

# èƒŒæ™¯åŸ·è¡Œå„ç¨®ç›£æ§
htop &
nvidia-smi -l 1 &

# ç­‰å¾…ä½¿ç”¨è€…ä¸­æ–·
wait
```

### ğŸš€ é€šç”¨è¨“ç·´æŒ‡ä»¤æ ¼å¼

#### åŸºæœ¬è¨“ç·´æŒ‡ä»¤
```bash
# åŸºæœ¬åŸ·è¡Œ
python train.py

# æŒ‡å®š GPU
CUDA_VISIBLE_DEVICES=0 python train.py

# èƒŒæ™¯åŸ·è¡Œ
nohup python train.py > training.log 2>&1 &

# å³æ™‚æŸ¥çœ‹æ—¥èªŒ
tail -f training.log
```

#### åƒæ•¸åŒ–åŸ·è¡Œ
```bash
# æ¨™æº–åƒæ•¸æ ¼å¼
python train.py \
    --gpu 0 \
    --batch-size 64 \
    --epochs 100 \
    --learning-rate 0.001 \
    --model-dir ./models \
    --data-dir ./data

# ç’°å¢ƒè®Šæ•¸æ§åˆ¶
export CUDA_VISIBLE_DEVICES=0
export TF_CPP_MIN_LOG_LEVEL=2
python train.py --config config.yaml
```

#### åˆ†å¸ƒå¼è¨“ç·´ (å¤š GPU)
```bash
# TensorFlow åˆ†å¸ƒå¼
python -m tensorflow.distribute.strategy train.py

# PyTorch åˆ†å¸ƒå¼
python -m torch.distributed.launch --nproc_per_node=2 train.py
```

### ğŸ› ï¸ é™¤éŒ¯æŒ‡ä»¤

#### è¨˜æ†¶é«”å•é¡Œé™¤éŒ¯
```bash
# æ¸…ç† GPU è¨˜æ†¶é«”
nvidia-smi --gpu-reset

# æª¢æŸ¥ç¨‹åºä½”ç”¨
nvidia-smi pmon -c 1

# å¼·åˆ¶çµæŸ GPU ç¨‹åº
sudo kill -9 <PID>
```

#### Python ç¨‹åºç®¡ç†
```bash
# æŸ¥çœ‹ Python ç¨‹åº
ps aux | grep python

# çµæŸç‰¹å®šç¨‹åº
pkill -f "python train.py"

# æŸ¥çœ‹è³‡æºä½”ç”¨
pidstat -r -p <PID>
```

#### æ—¥èªŒèˆ‡é™¤éŒ¯
```bash
# å³æ™‚æ—¥èªŒæŸ¥çœ‹
tail -f training.log

# éŒ¯èª¤æ—¥èªŒç¯©é¸
grep -i error training.log
grep -i "out of memory" training.log

# ç³»çµ±æ—¥èªŒæª¢æŸ¥
dmesg | grep -i nvidia  # Linux
```

---

## 4. æ–° Claude å”ä½œæŒ‡å—

### ğŸ’» ç¡¬é«”ç’°å¢ƒæè¿°æ¨¡æ¿

è¤‡è£½ä»¥ä¸‹æ¨¡æ¿ï¼Œå¡«å…¥ä½ çš„å…·é«”è³‡è¨Šçµ¦æ–°çš„ Claudeï¼š

```markdown
## æˆ‘çš„æ·±åº¦å­¸ç¿’ç’°å¢ƒ

**ç¡¬é«”é…ç½®:**
- GPU: NVIDIA GeForce GTX 1660 Super
- VRAM: 6GB (å¯ç”¨ç´„ 4-4.5GB)
- è¨ˆç®—èƒ½åŠ›: 7.5 (Turing æ¶æ§‹)
- ä¸»æ©Ÿè¨˜æ†¶é«”: [å¡«å…¥ä½ çš„ RAM å¤§å°]
- CPU: [å¡«å…¥ä½ çš„ CPU å‹è™Ÿ]

**è»Ÿé«”ç’°å¢ƒ:**
- ä½œæ¥­ç³»çµ±: Windows 11
- NVIDIA é©…å‹•: 560.94
- CUDA ç‰ˆæœ¬: 12.6
- Python: 3.10.x
- ä¸»è¦æ¡†æ¶: TensorFlow-GPU 2.10.1 (å·²ç¢ºèªæ­£å¸¸é‹è¡Œ)

**ç’°å¢ƒç‹€æ…‹:**
- âœ… GPU é©—è­‰é€šé (nvidia-smi æ­£å¸¸)
- âœ… TensorFlow GPU æ”¯æ´ç¢ºèª
- âœ… è¨˜æ†¶é«”å¢é•·è¨­å®šå®Œæˆ
- âœ… åŸºæœ¬è¨ˆç®—æ¸¬è©¦é€šé

**æ•ˆèƒ½åŸºæº–:**
- çŸ©é™£é‹ç®— (2000x2000): [å¡«å…¥æ¸¬è©¦æ™‚é–“]
- å¯ç”¨æ‰¹æ¬¡å¤§å°: 32-64 (ä¾æ¨¡å‹è€Œå®š)
- å…¸å‹è¨“ç·´é€Ÿåº¦: [å¦‚å·²çŸ¥]
```

### ğŸ¯ å•é¡Œæè¿°æ¨¡æ¿

æ ¹æ“šä½ è¦è§£æ±ºçš„å•é¡Œé¡å‹ï¼Œé¸æ“‡å°æ‡‰æ¨¡æ¿ï¼š

#### è¨“ç·´å•é¡Œæ¨¡æ¿
```markdown
## è¨“ç·´å•é¡Œæè¿°

**ä»»å‹™é¡å‹:** [ä¾‹å¦‚: åœ–åƒåˆ†é¡/æ–‡å­—åˆ†é¡/ç›®æ¨™æª¢æ¸¬/å…¶ä»–]

**è³‡æ–™è¦æ¨¡:**
- è¨“ç·´æ¨£æœ¬æ•¸: [æ•¸é‡]
- é©—è­‰æ¨£æœ¬æ•¸: [æ•¸é‡]
- è³‡æ–™ç¶­åº¦: [ä¾‹å¦‚: 224x224x3 åœ–ç‰‡ / 512 åºåˆ—é•·åº¦æ–‡å­—]

**ç›®å‰ç‹€æ³:**
- æ¨¡å‹æ¶æ§‹: [ç°¡è¿°ä½¿ç”¨çš„æ¨¡å‹]
- é‡åˆ°çš„å•é¡Œ: [å…·é«”æè¿°]
- ç•¶å‰æ•ˆèƒ½: [æº–ç¢ºç‡/æå¤±å€¼/å…¶ä»–æŒ‡æ¨™]
- æœŸæœ›ç›®æ¨™: [æƒ³é”åˆ°çš„æ•ˆæœ]

**å·²å˜—è©¦çš„æ–¹æ³•:**
- [åˆ—å‡ºå·²ç¶“è©¦éçš„æŠ€è¡“/åƒæ•¸]
- [æ•ˆæœå¦‚ä½•]

**è³‡æºé™åˆ¶:**
- è¨“ç·´æ™‚é–“é ç®—: [ä¾‹å¦‚: å¸Œæœ›åœ¨ X å°æ™‚å…§å®Œæˆ]
- è¨˜æ†¶é«”é™åˆ¶: 4GB VRAM
- å…¶ä»–é™åˆ¶: [å¦‚æœ‰]
```

#### ç’°å¢ƒå•é¡Œæ¨¡æ¿
```markdown
## ç’°å¢ƒå•é¡Œæè¿°

**å•é¡Œé¡å‹:** [ä¾‹å¦‚: å®‰è£å•é¡Œ/ç›¸å®¹æ€§å•é¡Œ/æ•ˆèƒ½å•é¡Œ]

**å…·é«”ç—‡ç‹€:**
- éŒ¯èª¤è¨Šæ¯: [å®Œæ•´è²¼ä¸ŠéŒ¯èª¤è¨Šæ¯]
- å‡ºç¾æ™‚æ©Ÿ: [ä»€éº¼æ™‚å€™ç™¼ç”Ÿ]
- ç’°å¢ƒç‹€æ…‹: [ç›¸é—œç’°å¢ƒè³‡è¨Š]

**å¾©ç¾æ­¥é©Ÿ:**
1. [æ­¥é©Ÿä¸€]
2. [æ­¥é©ŸäºŒ]
3. [å•é¡Œå‡ºç¾]

**å·²å˜—è©¦çš„è§£æ±ºæ–¹æ³•:**
- [æ–¹æ³•ä¸€åŠçµæœ]
- [æ–¹æ³•äºŒåŠçµæœ]
```

### ğŸ“ æª”æ¡ˆæä¾›æ¸…å–®

#### å¿…è¦æª”æ¡ˆ
- **è¨“ç·´è³‡æ–™**: å®Œæ•´è³‡æ–™é›†æˆ–ä»£è¡¨æ€§æ¨£æœ¬
- **ç•¶å‰ç¨‹å¼ç¢¼**: ä¸»è¦çš„è¨“ç·´è…³æœ¬
- **éŒ¯èª¤æ—¥èªŒ**: å¦‚æœæœ‰å•é¡Œï¼Œæä¾›å®Œæ•´éŒ¯èª¤è¨Šæ¯

#### å¯é¸æª”æ¡ˆ (æœ‰åŠ©æ–¼æ›´å¥½ç†è§£)
- **è³‡æ–™é›†æè¿°**: README æˆ–è³‡æ–™èªªæ˜æ–‡ä»¶
- **ä¹‹å‰çš„å¯¦é©—çµæœ**: è¨“ç·´æ›²ç·šã€æ··æ·†çŸ©é™£ç­‰
- **æ¨¡å‹æª”æ¡ˆ**: å¦‚æœæœ‰é è¨“ç·´æˆ–éƒ¨åˆ†è¨“ç·´çš„æ¨¡å‹
- **é…ç½®æª”æ¡ˆ**: config.yaml æˆ– settings.py

#### æª”æ¡ˆæ ¼å¼èªªæ˜
```markdown
**è³‡æ–™é›†æ ¼å¼ç¯„ä¾‹:**
- åœ–åƒåˆ†é¡: ImageFolder çµæ§‹æˆ– CSV ç´¢å¼•æª”
- æ–‡å­—åˆ†é¡: JSON/CSV æ ¼å¼ï¼ŒåŒ…å« text å’Œ label æ¬„ä½
- å…¶ä»–æ ¼å¼: [å…·é«”èªªæ˜]

**æª”æ¡ˆå¤§å°é™åˆ¶:**
- å–®æª”æœ€å¤§: [æŸ¥çœ‹ Claude ç•¶å‰é™åˆ¶]
- ç¸½å¤§å°å»ºè­°: [å£“ç¸®å¤§æª”æ¡ˆæˆ–æä¾›æ¨£æœ¬]
```

### ğŸ”§ æŠ€è¡“èƒŒæ™¯èªªæ˜

#### ç¶“é©—æ°´å¹³æè¿°
```markdown
**æˆ‘çš„æŠ€è¡“èƒŒæ™¯:**
- æ·±åº¦å­¸ç¿’ç¶“é©—: [åˆå­¸è€…/ä¸­ç´š/é€²éš]
- ç†Ÿæ‚‰çš„æ¡†æ¶: [TensorFlow/PyTorch/å…¶ä»–]
- åå¥½çš„å­¸ç¿’æ–¹å¼: [ä»£ç¢¼ç¯„ä¾‹/ç†è«–è§£é‡‹/æ­¥é©ŸæŒ‡å°]

**å¸Œæœ›çš„å”åŠ©æ–¹å¼:**
- âœ… æä¾›å®Œæ•´å¯åŸ·è¡Œçš„ç¨‹å¼ç¢¼
- âœ… åŒ…å«è©³ç´°è¨»è§£èªªæ˜
- âœ… æä¾›é™¤éŒ¯å’Œç›£æ§æ–¹æ³•
- âœ… èªªæ˜é—œéµåƒæ•¸çš„èª¿æ•´æ–¹å‘
```

#### å°ˆæ¡ˆç›®æ¨™èªªæ˜
```markdown
**å°ˆæ¡ˆç›®æ¨™:**
- ä¸»è¦ç›®æ¨™: [ä¾‹å¦‚: é”åˆ° X% æº–ç¢ºç‡]
- æ¬¡è¦ç›®æ¨™: [ä¾‹å¦‚: è¨“ç·´æ™‚é–“æ§åˆ¶åœ¨ X å°æ™‚å…§]
- éƒ¨ç½²éœ€æ±‚: [æ˜¯å¦éœ€è¦è€ƒæ…®éƒ¨ç½²ç’°å¢ƒ]

**æ™‚é–“å®‰æ’:**
- é–‹ç™¼æ™‚é™: [å¦‚æœ‰]
- é‡Œç¨‹ç¢‘: [éšæ®µæ€§ç›®æ¨™]
```

---

## 5. æ•…éšœæ’é™¤æŒ‡å—

### âŒ å¸¸è¦‹éŒ¯èª¤èˆ‡è§£æ±º

#### CUDA Out of Memory éŒ¯èª¤
**ç—‡ç‹€**: 
```
RuntimeError: CUDA out of memory. Tried to allocate XXX MiB
```

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# æ–¹æ³• 1: æ¸›å°‘æ‰¹æ¬¡å¤§å°
batch_size = 16  # å¾ 64 é™åˆ° 16

# æ–¹æ³• 2: è¨­å®šè¨˜æ†¶é«”å¢é•·
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    tf.config.experimental.set_memory_growth(gpus[0], True)

# æ–¹æ³• 3: æ¸…ç†è¨˜æ†¶é«”
import gc
tf.keras.backend.clear_session()
gc.collect()

# æ–¹æ³• 4: ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´
policy = tf.keras.mixed_precision.Policy('mixed_float16')
tf.keras.mixed_precision.set_global_policy(policy)
```

#### GPU Not Detected éŒ¯èª¤
**ç—‡ç‹€**:
```python
tf.config.list_physical_devices('GPU')  # è¿”å›ç©ºåˆ—è¡¨
```

**æª¢æŸ¥æ­¥é©Ÿ**:
```bash
# 1. æª¢æŸ¥é©…å‹•
nvidia-smi

# 2. æª¢æŸ¥ CUDA
nvcc --version

# 3. æª¢æŸ¥ TensorFlow ç‰ˆæœ¬
python -c "import tensorflow as tf; print(tf.__version__)"

# 4. é‡æ–°å®‰è£ GPU ç‰ˆæœ¬
pip uninstall tensorflow
pip install tensorflow-gpu==2.10.1
```

#### ç‰ˆæœ¬ä¸ç›¸å®¹éŒ¯èª¤
**ç—‡ç‹€**:
```
Could not load dynamic library 'libcudnn.so.X'
```

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# æª¢æŸ¥ç‰ˆæœ¬ç›¸å®¹æ€§
python -c "import tensorflow as tf; print(tf.test.is_built_with_cuda())"

# é™ç´šåˆ°ç©©å®šç‰ˆæœ¬
pip install tensorflow-gpu==2.10.1

# æˆ–ä½¿ç”¨ conda è‡ªå‹•è™•ç†ä¾è³´
conda install tensorflow-gpu -c conda-forge
```

### ğŸ”§ VRAM ä¸è¶³è™•ç†

#### æ¨¡å‹è¼•é‡åŒ–ç­–ç•¥
```python
# 1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹
model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3))

# 2. æ¸›å°‘å±¤æ•¸æˆ–ç¥ç¶“å…ƒæ•¸é‡
model = Sequential([
    Dense(128, activation='relu'),  # å¾ 512 æ¸›å°‘åˆ° 128
    Dropout(0.3),
    Dense(num_classes, activation='softmax')
])

# 3. ä½¿ç”¨ DepthwiseConv2D
tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same')
```

#### æ‰¹æ¬¡å¤§å°å„ªåŒ–
```python
# å‹•æ…‹æ‰¹æ¬¡å¤§å°èª¿æ•´
def find_optimal_batch_size(model, X_sample, y_sample, max_batch=128):
    batch_size = max_batch
    while batch_size >= 1:
        try:
            model.fit(X_sample[:batch_size], y_sample[:batch_size], epochs=1, verbose=0)
            print(f"æœ€ä½³æ‰¹æ¬¡å¤§å°: {batch_size}")
            return batch_size
        except Exception as e:
            if "out of memory" in str(e).lower():
                batch_size //= 2
                print(f"å˜—è©¦æ‰¹æ¬¡å¤§å°: {batch_size}")
            else:
                raise e
    return 1
```

#### æ··åˆç²¾åº¦è¨“ç·´
```python
# TensorFlow æ··åˆç²¾åº¦è¨­å®š
policy = tf.keras.mixed_precision.Policy('mixed_float16')
tf.keras.mixed_precision.set_global_policy(policy)

# ç¢ºä¿è¼¸å‡ºå±¤ä½¿ç”¨ float32
model.add(Dense(num_classes, activation='softmax', dtype='float32'))

# æå¤±ç¸®æ”¾
optimizer = tf.keras.optimizers.Adam()
optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)
```

#### æ¢¯åº¦ç´¯ç©æŠ€è¡“
```python
# æ¨¡æ“¬æ›´å¤§æ‰¹æ¬¡å¤§å°çš„æ¢¯åº¦ç´¯ç©
def train_with_gradient_accumulation(model, dataset, accumulation_steps=4):
    optimizer = tf.keras.optimizers.Adam()
    
    @tf.function
    def train_step(x, y):
        with tf.GradientTape() as tape:
            predictions = model(x, training=True)
            loss = loss_fn(y, predictions) / accumulation_steps
        
        gradients = tape.gradient(loss, model.trainable_variables)
        return loss, gradients
    
    accumulated_gradients = [tf.Variable(tf.zeros_like(var)) 
                           for var in model.trainable_variables]
    
    for step, (x, y) in enumerate(dataset):
        loss, gradients = train_step(x, y)
        
        # ç´¯ç©æ¢¯åº¦
        for i, grad in enumerate(gradients):
            accumulated_gradients[i].assign_add(grad)
        
        # æ¯ accumulation_steps æ­¥æ›´æ–°ä¸€æ¬¡
        if (step + 1) % accumulation_steps == 0:
            optimizer.apply_gradients(zip(accumulated_gradients, model.trainable_variables))
            # é‡ç½®ç´¯ç©æ¢¯åº¦
            for acc_grad in accumulated_gradients:
                acc_grad.assign(tf.zeros_like(acc_grad))
```

### ğŸš¨ ç·Šæ€¥æ¢å¾©æ–¹æ¡ˆ

#### ç’°å¢ƒå®Œå…¨é‡å»º
```bash
# 1. å‚™ä»½é‡è¦æª”æ¡ˆ
cp -r important_files/ backup/

# 2. ç§»é™¤èˆŠç’°å¢ƒ
conda remove --name deeplearning --all -y

# 3. é‡æ–°å‰µå»ºç’°å¢ƒ
conda create --name deeplearning python=3.10 -y
conda activate deeplearning

# 4. é‡æ–°å®‰è£å¥—ä»¶
pip install tensorflow-gpu==2.10.1
pip install -r requirements.txt

# 5. é©—è­‰ç’°å¢ƒ
python gpu_test.py
```

#### å¥—ä»¶é™ç´šæ–¹æ¡ˆ
```bash
# TensorFlow ç‰ˆæœ¬é™ç´š
pip install tensorflow-gpu==2.8.0  # æ›´ç©©å®šçš„ç‰ˆæœ¬

# CUDA å·¥å…·åŒ…é™ç´š
# ä¸‹è¼‰ä¸¦å®‰è£ CUDA 11.2

# æ•´é«”é™ç´šåˆ°ç©©å®šçµ„åˆ
pip install tensorflow-gpu==2.8.0 numpy==1.21.6 pandas==1.3.5
```

#### ç³»çµ±é‚„åŸé» (Windows)
```powershell
# å‰µå»ºé‚„åŸé»
Checkpoint-Computer -Description "Deep Learning Environment Backup"

# æŸ¥çœ‹é‚„åŸé»
Get-ComputerRestorePoint

# æ¢å¾©åˆ°ç‰¹å®šé‚„åŸé»
Restore-Computer -RestorePoint X
```

---

## 6. æª”æ¡ˆç®¡ç†å»ºè­°

### ğŸ“‚ å°ˆæ¡ˆçµæ§‹æ¨¡æ¿

#### æ¨™æº–æ·±åº¦å­¸ç¿’å°ˆæ¡ˆçµæ§‹
```
project_name/
â”œâ”€â”€ data/                   # è³‡æ–™æª”æ¡ˆ
â”‚   â”œâ”€â”€ raw/               # åŸå§‹è³‡æ–™
â”‚   â”œâ”€â”€ processed/         # è™•ç†å¾Œè³‡æ–™
â”‚   â”œâ”€â”€ external/          # å¤–éƒ¨è³‡æ–™é›†
â”‚   â””â”€â”€ interim/           # ä¸­é–“è™•ç†çµæœ
â”œâ”€â”€ models/                # è¨“ç·´å¥½çš„æ¨¡å‹
â”‚   â”œâ”€â”€ checkpoints/       # è¨“ç·´æª¢æŸ¥é»
â”‚   â”œâ”€â”€ final/            # æœ€çµ‚æ¨¡å‹
â”‚   â””â”€â”€ experiments/       # å¯¦é©—æ¨¡å‹
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”‚   â”œâ”€â”€ exploratory/       # è³‡æ–™æ¢ç´¢
â”‚   â”œâ”€â”€ modeling/         # æ¨¡å‹é–‹ç™¼
â”‚   â””â”€â”€ evaluation/       # çµæœè©•ä¼°
â”œâ”€â”€ src/                   # åŸå§‹ç¢¼
â”‚   â”œâ”€â”€ data/             # è³‡æ–™è™•ç†è…³æœ¬
â”‚   â”œâ”€â”€ features/         # ç‰¹å¾µå·¥ç¨‹
â”‚   â”œâ”€â”€ models/           # æ¨¡å‹å®šç¾©
â”‚   â”œâ”€â”€ visualization/    # è¦–è¦ºåŒ–å·¥å…·
â”‚   â””â”€â”€ utils/            # å·¥å…·å‡½æ•¸
â”œâ”€â”€ outputs/               # çµæœè¼¸å‡º
â”‚   â”œâ”€â”€ figures/          # åœ–è¡¨
â”‚   â”œâ”€â”€ reports/          # å ±å‘Š
â”‚   â””â”€â”€ predictions/      # é æ¸¬çµæœ
â”œâ”€â”€ logs/                  # è¨“ç·´æ—¥èªŒ
â”‚   â”œâ”€â”€ tensorboard/      # TensorBoard æ—¥èªŒ
â”‚   â”œâ”€â”€ training/         # è¨“ç·´æ—¥èªŒ
â”‚   â””â”€â”€ error/            # éŒ¯èª¤æ—¥èªŒ
â”œâ”€â”€ configs/               # é…ç½®æª”æ¡ˆ
â”‚   â”œâ”€â”€ model_config.yaml # æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ data_config.yaml  # è³‡æ–™é…ç½®
â”‚   â””â”€â”€ training_config.yaml # è¨“ç·´é…ç½®
â”œâ”€â”€ tests/                 # æ¸¬è©¦æª”æ¡ˆ
â”œâ”€â”€ requirements.txt       # Python ä¾è³´
â”œâ”€â”€ environment.yml        # Conda ç’°å¢ƒ
â”œâ”€â”€ README.md             # å°ˆæ¡ˆèªªæ˜
â”œâ”€â”€ .gitignore            # Git å¿½ç•¥æª”æ¡ˆ
â””â”€â”€ setup.py              # å¥—ä»¶å®‰è£è…³æœ¬
```

#### å¿«é€Ÿå»ºç«‹å°ˆæ¡ˆçµæ§‹
```bash
# å»ºç«‹å°ˆæ¡ˆç›®éŒ„è…³æœ¬ create_project.sh
#!/bin/bash
PROJECT_NAME=$1

mkdir -p $PROJECT_NAME/{data/{raw,processed,external,interim},models/{checkpoints,final,experiments},notebooks/{exploratory,modeling,evaluation},src/{data,features,models,visualization,utils},outputs/{figures,reports,predictions},logs/{tensorboard,training,error},configs,tests}

cd $PROJECT_NAME

# å»ºç«‹åŸºæœ¬æª”æ¡ˆ
touch README.md .gitignore requirements.txt environment.yml setup.py
touch configs/{model_config.yaml,data_config.yaml,training_config.yaml}

echo "å°ˆæ¡ˆ $PROJECT_NAME çµæ§‹å»ºç«‹å®Œæˆï¼"
```

### ğŸ“ å‘½åè¦ç¯„

#### æª”æ¡ˆå‘½åè¦ç¯„
```bash
# æ¨¡å‹æª”æ¡ˆå‘½å
model_architecture_dataset_version_metric.h5
# ç¯„ä¾‹: resnet50_cifar10_v1_acc92.h5

# å¯¦é©—è¨˜éŒ„å‘½å
experiment_YYYYMMDD_HHMM_description.json
# ç¯„ä¾‹: experiment_20250607_1430_lstm_emotion_classification.json

# è³‡æ–™æª”æ¡ˆå‘½å
dataset_preprocessing_version.csv
# ç¯„ä¾‹: emotions_cleaned_v2.csv

# æ—¥èªŒæª”æ¡ˆå‘½å
training_YYYYMMDD_HHMM.log
# ç¯„ä¾‹: training_20250607_1430.log
```

#### ç‰ˆæœ¬ç®¡ç†è¦ç¯„
```bash
# æ¨¡å‹ç‰ˆæœ¬è™Ÿè¦å‰‡
v[major].[minor].[patch]
# v1.0.0 - ç¬¬ä¸€å€‹ç©©å®šç‰ˆæœ¬
# v1.1.0 - æ–°å¢åŠŸèƒ½
# v1.1.1 - éŒ¯èª¤ä¿®å¾©

# Git æ¨™ç±¤è¦ç¯„
git tag -a v1.0.0 -m "First stable model release"
git tag -a exp-20250607 -m "Emotion classification experiment"
```

#### é…ç½®æª”æ¡ˆå‘½å
```yaml
# config/model_config.yaml
model:
  name: "lstm_classifier"
  version: "v1.0.0"
  architecture: "bidirectional_lstm"
  
# config/data_config.yaml  
data:
  dataset: "emotion_classification"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1

# config/training_config.yaml
training:
  epochs: 100
  batch_size: 64
  learning_rate: 0.001
  optimizer: "adam"
```

### ğŸ’¾ å‚™ä»½ç­–ç•¥

#### æœ¬åœ°å‚™ä»½æ–¹æ¡ˆ
```bash
# æ¯æ—¥è‡ªå‹•å‚™ä»½è…³æœ¬
#!/bin/bash
BACKUP_DIR="/backup/deeplearning"
PROJECT_DIR="/path/to/project"
DATE=$(date +%Y%m%d)

# å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p $BACKUP_DIR/$DATE

# å‚™ä»½é‡è¦æª”æ¡ˆ
rsync -av --exclude='*.log' --exclude='__pycache__' \
  $PROJECT_DIR/ $BACKUP_DIR/$DATE/

# å£“ç¸®å‚™ä»½
tar -czf $BACKUP_DIR/$DATE.tar.gz $BACKUP_DIR/$DATE/
rm -rf $BACKUP_DIR/$DATE/

# ä¿ç•™æœ€è¿‘ 7 å¤©çš„å‚™ä»½
find $BACKUP_DIR -name "*.tar.gz" -mtime +7 -delete

echo "å‚™ä»½å®Œæˆ: $BACKUP_DIR/$DATE.tar.gz"
```

#### é›²ç«¯å‚™ä»½æ–¹æ¡ˆ
```bash
# Google Drive åŒæ­¥ (rclone)
rclone sync /path/to/project googledrive:backup/deeplearning

# GitHub è‡ªå‹•æ¨é€
git add .
git commit -m "Auto backup $(date)"
git push origin main

# æ¨¡å‹æª”æ¡ˆ (ä½¿ç”¨ DVC)
dvc add models/final/
git add models/final/.gitignore models/final/.dvc
git commit -m "Update model files"
dvc push
```

#### é‡è¦æª”æ¡ˆå„ªå…ˆç´š
```bash
# é«˜å„ªå…ˆç´š (æ¯æ—¥å‚™ä»½)
- åŸå§‹ç¢¼ (src/)
- é…ç½®æª”æ¡ˆ (configs/)
- è¨“ç·´è…³æœ¬
- README.md

# ä¸­å„ªå…ˆç´š (æ¯é€±å‚™ä»½)  
- è™•ç†å¾Œè³‡æ–™ (data/processed/)
- æœ€çµ‚æ¨¡å‹ (models/final/)
- é‡è¦çµæœ (outputs/reports/)

# ä½å„ªå…ˆç´š (æŒ‰éœ€å‚™ä»½)
- åŸå§‹è³‡æ–™ (é€šå¸¸ä¾†æºç©©å®š)
- å¯¦é©—æ¨¡å‹ (models/experiments/)
- æ—¥èªŒæª”æ¡ˆ (å¯é‡æ–°ç”Ÿæˆ)
```

### ğŸ—‚ï¸ å¤§æª”æ¡ˆè™•ç†

#### å¤§è³‡æ–™é›†ç®¡ç†
```bash
# ä½¿ç”¨ Git LFS ç®¡ç†å¤§æª”æ¡ˆ
git lfs install
git lfs track "*.h5"
git lfs track "*.pkl"
git lfs track "data/raw/*"

# .gitattributes æª”æ¡ˆå…§å®¹
*.h5 filter=lfs diff=lfs merge=lfs -text
*.pkl filter=lfs diff=lfs merge=lfs -text
data/raw/* filter=lfs diff=lfs merge=lfs -text
```

#### æª”æ¡ˆå£“ç¸®ç­–ç•¥
```bash
# è³‡æ–™æª”æ¡ˆå£“ç¸®
# JSON æª”æ¡ˆ
gzip large_dataset.json  # é€šå¸¸å¯æ¸›å°‘ 70-80%

# åœ–ç‰‡è³‡æ–™é›†
tar -czf images.tar.gz images/  # è¦–å…§å®¹è€Œå®š

# NumPy é™£åˆ—
python -c "
import numpy as np
data = np.load('large_array.npy')
np.savez_compressed('large_array.npz', data=data)
"

# æ¨¡å‹æª”æ¡ˆ
# TensorFlow SavedModel æ ¼å¼é€šå¸¸å·²æœ€ä½³åŒ–
# å¯è€ƒæ…®é‡åŒ–æ¸›å°‘å¤§å°
```

#### åˆ†å‰²èˆ‡åˆä½µ
```bash
# å¤§æª”æ¡ˆåˆ†å‰²
split -b 100M large_file.h5 large_file.h5.part_

# æª”æ¡ˆåˆä½µ
cat large_file.h5.part_* > large_file.h5

# Python å¯¦ç¾
def split_large_file(file_path, chunk_size=100*1024*1024):  # 100MB
    with open(file_path, 'rb') as f:
        chunk_num = 0
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
            with open(f"{file_path}.part_{chunk_num:03d}", 'wb') as chunk_file:
                chunk_file.write(chunk)
            chunk_num += 1
```

#### ç‰ˆæœ¬æ§åˆ¶æœ€ä½³å¯¦è¸
```bash
# .gitignore ç¯„ä¾‹
# è³‡æ–™æª”æ¡ˆ
data/raw/
data/interim/
*.csv
*.h5
*.pkl
*.npy

# æ¨¡å‹æª”æ¡ˆ
models/checkpoints/
models/experiments/
*.ckpt
*.pb

# æ—¥èªŒæª”æ¡ˆ
logs/
*.log
tensorboard/

# ç³»çµ±æª”æ¡ˆ
__pycache__/
*.pyc
.DS_Store
Thumbs.db

# IDE æª”æ¡ˆ
.vscode/
.idea/
*.swp

# ç’°å¢ƒæª”æ¡ˆ
.env
```

#### æ–‡ä»¶åŒ–æœ€ä½³å¯¦è¸
```markdown
# README.md æ¨¡æ¿
# å°ˆæ¡ˆåç¨±

## ç°¡ä»‹
[å°ˆæ¡ˆç°¡è¿°]

## ç’°å¢ƒéœ€æ±‚
- Python 3.10+
- NVIDIA GPU (å»ºè­° GTX 1660 Super æˆ–æ›´é«˜)
- CUDA 11.8+
- è¨˜æ†¶é«”: 16GB+ å»ºè­°

## å®‰è£æ­¥é©Ÿ
```bash
conda create --name project_name python=3.10
conda activate project_name
pip install -r requirements.txt
```

## ä½¿ç”¨æ–¹æ³•
```bash
# è³‡æ–™æº–å‚™
python src/data/prepare_data.py

# æ¨¡å‹è¨“ç·´
python src/models/train.py --config configs/model_config.yaml

# æ¨¡å‹è©•ä¼°
python src/models/evaluate.py --model models/final/best_model.h5
```

## å°ˆæ¡ˆçµæ§‹
[æª”æ¡ˆçµæ§‹èªªæ˜]

## çµæœ
[å¯¦é©—çµæœèˆ‡æ•ˆèƒ½æŒ‡æ¨™]

## æˆæ¬Š
[æˆæ¬Šè³‡è¨Š]
```

---

## ğŸ“š é™„éŒ„

### ğŸ”— æœ‰ç”¨çš„é€£çµ

#### å®˜æ–¹æ–‡ä»¶
- [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit)
- [TensorFlow GPU æ”¯æ´æŒ‡å—](https://www.tensorflow.org/install/gpu)
- [PyTorch å®‰è£æŒ‡å—](https://pytorch.org/get-started/locally/)

#### ç¤¾ç¾¤è³‡æº
- [TensorFlow GitHub](https://github.com/tensorflow/tensorflow)
- [PyTorch Forums](https://discuss.pytorch.org/)
- [NVIDIA Developer Forums](https://forums.developer.nvidia.com/)

#### æ•ˆèƒ½å„ªåŒ–
- [TensorFlow æ•ˆèƒ½æŒ‡å—](https://www.tensorflow.org/guide/gpu_performance_analysis)
- [GPU è¨˜æ†¶é«”å„ªåŒ–](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)

### ğŸ“ æ”¯æ´ç®¡é“

#### å¸¸è¦‹å•é¡Œ
1. **GPU ç„¡æ³•è¢«æª¢æ¸¬**ï¼šæª¢æŸ¥é©…å‹•å’Œ CUDA ç‰ˆæœ¬ç›¸å®¹æ€§
2. **è¨˜æ†¶é«”ä¸è¶³**ï¼šæ¸›å°‘æ‰¹æ¬¡å¤§å°æˆ–ä½¿ç”¨æ··åˆç²¾åº¦
3. **è¨“ç·´é€Ÿåº¦æ…¢**ï¼šæª¢æŸ¥ GPU ä½¿ç”¨ç‡å’Œ I/O ç“¶é ¸
4. **æ¨¡å‹æ”¶æ–‚å›°é›£**ï¼šèª¿æ•´å­¸ç¿’ç‡å’Œæ­£å‰‡åŒ–åƒæ•¸

#### æ•…éšœæ’é™¤æµç¨‹
1. ç¢ºèªç¡¬é«”ç‹€æ…‹ (`nvidia-smi`)
2. æª¢æŸ¥è»Ÿé«”ç‰ˆæœ¬ç›¸å®¹æ€§
3. æŸ¥çœ‹éŒ¯èª¤æ—¥èªŒå’Œå †ç–Šè¿½è¹¤
4. æœå°‹ç›¸é—œçš„ GitHub Issues
5. åœ¨ç›¸é—œè«–å£‡æå•

---

## ğŸ“‹ æª¢æŸ¥æ¸…å–®

### âœ… ç’°å¢ƒè¨­å®šæª¢æŸ¥æ¸…å–®

- [ ] NVIDIA é©…å‹•å·²å®‰è£ (ç‰ˆæœ¬ 460+)
- [ ] CUDA Toolkit å·²å®‰è£ä¸¦é…ç½®ç’°å¢ƒè®Šæ•¸
- [ ] cuDNN å·²ä¸‹è¼‰ä¸¦é…ç½®
- [ ] Python è™›æ“¬ç’°å¢ƒå·²å»ºç«‹
- [ ] TensorFlow-GPU æˆ– PyTorch å·²å®‰è£
- [ ] GPU æª¢æ¸¬æ¸¬è©¦é€šé
- [ ] è¨˜æ†¶é«”å¢é•·è¨­å®šå·²é…ç½®
- [ ] åŸºæœ¬é‹ç®—æ¸¬è©¦é€šé

### âœ… å°ˆæ¡ˆé–‹ç™¼æª¢æŸ¥æ¸…å–®

- [ ] å°ˆæ¡ˆçµæ§‹å·²å»ºç«‹
- [ ] requirements.txt å·²å»ºç«‹
- [ ] .gitignore å·²é…ç½®
- [ ] README.md å·²æ’°å¯«
- [ ] å‚™ä»½ç­–ç•¥å·²å¯¦æ–½
- [ ] ç›£æ§è…³æœ¬å·²æº–å‚™
- [ ] æ¸¬è©¦è³‡æ–™å·²æº–å‚™
- [ ] åŸºæº–æ¸¬è©¦å·²åŸ·è¡Œ

### âœ… å”ä½œæº–å‚™æª¢æŸ¥æ¸…å–®

- [ ] ç’°å¢ƒè³‡è¨Šå·²æ•´ç†
- [ ] å•é¡Œæè¿°å·²æº–å‚™
- [ ] ç›¸é—œæª”æ¡ˆå·²å‚™å¦¥
- [ ] æŠ€è¡“èƒŒæ™¯å·²èªªæ˜
- [ ] æœŸæœ›ç›®æ¨™å·²æ˜ç¢º
- [ ] æ™‚é–“é ç®—å·²è©•ä¼°

---

*æœ¬æŒ‡å—æœ€å¾Œæ›´æ–°ï¼š2025å¹´6æœˆ*  
*é©ç”¨æ–¼ NVIDIA GTX 1660 Super åŠé¡ä¼¼è¦æ ¼çš„ GPU*