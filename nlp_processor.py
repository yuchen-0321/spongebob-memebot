#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HanLP æ–·è©èˆ‡ JinaAI è©åµŒå…¥è™•ç†ç¨‹å¼
è™•ç†æµç¨‹:
1. è®€å– data.json æª”æ¡ˆ
2. ä½¿ç”¨ HanLP é€²è¡Œä¸­æ–‡æ–·è©
3. ä½¿ç”¨ JinaAI ç”¢ç”Ÿè©åµŒå…¥å‘é‡
4. è¼¸å‡ºè™•ç†å¾Œçš„çµæœç‚ºæ–°çš„ JSON æª”æ¡ˆ
"""

import json
import logging
from typing import List, Dict, Any
import numpy as np
import hanlp
from sentence_transformers import SentenceTransformer

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class NLPProcessor:
    """NLP è™•ç†å™¨é¡åˆ¥ï¼Œæ•´åˆ HanLP æ–·è©èˆ‡ JinaAI è©åµŒå…¥åŠŸèƒ½"""
    
    def __init__(self):
        """åˆå§‹åŒ– NLP è™•ç†å™¨"""
        logger.info("æ­£åœ¨åˆå§‹åŒ– NLP è™•ç†å™¨...")
        
        # åˆå§‹åŒ– HanLP æ–·è©å™¨ (ä½¿ç”¨ç¹é«”ä¸­æ–‡æ¨¡å‹)
        try:
            logger.info("è¼‰å…¥ HanLP æ–·è©æ¨¡å‹...")
            # ä½¿ç”¨ HanLP çš„ç¹é«”ä¸­æ–‡æ–·è©æ¨¡å‹
            self.tokenizer = hanlp.load(hanlp.pretrained.tok.SIGHAN2005_PKU_CONVSEG)
            logger.info("HanLP æ–·è©æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"HanLP æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
        
        # åˆå§‹åŒ– JinaAI è©åµŒå…¥æ¨¡å‹
        try:
            logger.info("è¼‰å…¥ JinaAI è©åµŒå…¥æ¨¡å‹...")
            # ä½¿ç”¨ JinaAI çš„å¤šèªè¨€è©åµŒå…¥æ¨¡å‹
            self.embedding_model = SentenceTransformer('jinaai/jina-embeddings-v2-base-zh')
            logger.info("JinaAI è©åµŒå…¥æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"JinaAI æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def tokenize_text(self, text: str) -> List[str]:
        """
        ä½¿ç”¨ HanLP å°æ–‡æœ¬é€²è¡Œæ–·è©
        
        Args:
            text (str): è¼¸å…¥æ–‡æœ¬
            
        Returns:
            List[str]: æ–·è©çµæœåˆ—è¡¨
        """
        try:
            # ä½¿ç”¨ HanLP é€²è¡Œæ–·è©
            tokens = self.tokenizer(text)
            # éæ¿¾ç©ºç™½å­—å…ƒå’Œç©ºå­—ä¸²
            tokens = [token.strip() for token in tokens if token.strip()]
            return tokens
        except Exception as e:
            logger.error(f"æ–·è©è™•ç†å¤±æ•—: {e}")
            return []
    
    def generate_embeddings(self, tokens: List[str]) -> List[float]:
        """
        ä½¿ç”¨ JinaAI æ¨¡å‹ç”¢ç”Ÿè©åµŒå…¥å‘é‡
        
        Args:
            tokens (List[str]): æ–·è©çµæœåˆ—è¡¨
            
        Returns:
            List[float]: è©åµŒå…¥å‘é‡
        """
        try:
            if not tokens:
                return []
            
            # å°‡ tokens çµ„åˆæˆå­—ä¸² (JinaAI æ¨¡å‹è¼¸å…¥æ ¼å¼)
            text = ' '.join(tokens)
            
            # ç”¢ç”Ÿè©åµŒå…¥å‘é‡
            embeddings = self.embedding_model.encode(text, convert_to_numpy=True)
            
            # è½‰æ›ç‚º Python list æ ¼å¼ä»¥ä¾¿ JSON åºåˆ—åŒ–
            return embeddings.tolist()
        except Exception as e:
            logger.error(f"è©åµŒå…¥ç”Ÿæˆå¤±æ•—: {e}")
            return []
    
    def process_single_item(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """
        è™•ç†å–®å€‹æ•¸æ“šé …ç›®
        
        Args:
            item (Dict[str, Any]): åŒ…å« text æ¬„ä½çš„å­—å…¸
            
        Returns:
            Dict[str, Any]: æ·»åŠ  tokens å’Œ embeddings æ¬„ä½çš„å­—å…¸
        """
        # è¤‡è£½åŸå§‹æ•¸æ“š
        result = item.copy()
        
        # æå–æ–‡æœ¬
        text = item.get('text', '')
        
        if not text:
            logger.warning("ç™¼ç¾ç©ºæ–‡æœ¬ï¼Œè·³éè™•ç†")
            result['tokens'] = []
            result['embeddings'] = []
            return result
        
        logger.info(f"è™•ç†æ–‡æœ¬: {text[:50]}...")
        
        # æ­¥é©Ÿ 1: HanLP æ–·è©
        tokens = self.tokenize_text(text)
        result['tokens'] = tokens
        logger.info(f"æ–·è©çµæœ: {tokens}")
        
        # æ­¥é©Ÿ 2: JinaAI è©åµŒå…¥
        embeddings = self.generate_embeddings(tokens)
        result['embeddings'] = embeddings
        logger.info(f"è©åµŒå…¥ç¶­åº¦: {len(embeddings) if embeddings else 0}")
        
        return result
    
    def process_json_file(self, input_file: str, output_file: str):
        """
        è™•ç†æ•´å€‹ JSON æª”æ¡ˆ
        
        Args:
            input_file (str): è¼¸å…¥æª”æ¡ˆè·¯å¾‘
            output_file (str): è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        try:
            # æ­¥é©Ÿ 1: è®€å– JSON æª”æ¡ˆ
            logger.info(f"è®€å–è¼¸å…¥æª”æ¡ˆ: {input_file}")
            with open(input_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            logger.info(f"æˆåŠŸè®€å– {len(data)} ç­†è³‡æ–™")
            
            # æ­¥é©Ÿ 2: è™•ç†æ¯ç­†è³‡æ–™
            processed_data = []
            for i, item in enumerate(data, 1):
                logger.info(f"è™•ç†ç¬¬ {i}/{len(data)} ç­†è³‡æ–™")
                processed_item = self.process_single_item(item)
                processed_data.append(processed_item)
            
            # æ­¥é©Ÿ 3: è¼¸å‡ºçµæœ
            logger.info(f"å„²å­˜çµæœåˆ°: {output_file}")
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(processed_data, f, ensure_ascii=False, indent=2)
            
            logger.info("è™•ç†å®Œæˆï¼")
            
        except FileNotFoundError:
            logger.error(f"æ‰¾ä¸åˆ°è¼¸å…¥æª”æ¡ˆ: {input_file}")
        except json.JSONDecodeError:
            logger.error(f"JSON æª”æ¡ˆæ ¼å¼éŒ¯èª¤: {input_file}")
        except Exception as e:
            logger.error(f"è™•ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    # æª”æ¡ˆè·¯å¾‘è¨­å®š
    input_file = "image_annotations.json"
    output_file = "processed_data.json"
    
    try:
        # å»ºç«‹ NLP è™•ç†å™¨
        processor = NLPProcessor()
        
        # è™•ç†æª”æ¡ˆ
        processor.process_json_file(input_file, output_file)
        
        print(f"\nâœ… è™•ç†å®Œæˆï¼")
        print(f"ğŸ“ è¼¸å…¥æª”æ¡ˆ: {input_file}")
        print(f"ğŸ“ è¼¸å‡ºæª”æ¡ˆ: {output_file}")
        
    except Exception as e:
        print(f"âŒ ç¨‹å¼åŸ·è¡Œå¤±æ•—: {e}")

if __name__ == "__main__":
    main()