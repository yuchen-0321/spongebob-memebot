#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PyTorch GPU ç’°å¢ƒæª¢æŸ¥è…³æœ¬
æª¢æŸ¥ PyTorch æ˜¯å¦æ­£ç¢ºå®‰è£ GPU æ”¯æ´
"""

import torch
import sys
import subprocess

print("=" * 60)
print("ğŸ” PyTorch GPU ç’°å¢ƒè¨ºæ–·")
print("=" * 60)

# 1. æª¢æŸ¥ PyTorch ç‰ˆæœ¬
print("\nğŸ“¦ PyTorch ç‰ˆæœ¬è³‡è¨Šï¼š")
print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
print(f"ç·¨è­¯çš„ CUDA ç‰ˆæœ¬: {torch.version.cuda}")
print(f"cuDNN ç‰ˆæœ¬: {torch.backends.cudnn.version()}")

# 2. æª¢æŸ¥ CUDA è¨­å‚™
if torch.cuda.is_available():
    print("\nâœ… GPU åµæ¸¬æˆåŠŸï¼")
    print(f"GPU æ•¸é‡: {torch.cuda.device_count()}")
    
    for i in range(torch.cuda.device_count()):
        print(f"\nGPU {i}:")
        print(f"  åç¨±: {torch.cuda.get_device_name(i)}")
        print(f"  è¨ˆç®—èƒ½åŠ›: {torch.cuda.get_device_capability(i)}")
        print(f"  ç¸½è¨˜æ†¶é«”: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB")
        
        # æª¢æŸ¥ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨
        if torch.cuda.is_available():
            print(f"  å·²ä½¿ç”¨è¨˜æ†¶é«”: {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB")
            print(f"  å¿«å–è¨˜æ†¶é«”: {torch.cuda.memory_reserved(i) / 1024**3:.2f} GB")
    
    # 3. æ¸¬è©¦ GPU é‹ç®—
    print("\nğŸ§® GPU é‹ç®—æ¸¬è©¦...")
    try:
        # å»ºç«‹æ¸¬è©¦å¼µé‡
        device = torch.device('cuda:0')
        x = torch.randn(1000, 1000).to(device)
        y = torch.randn(1000, 1000).to(device)
        
        # åŸ·è¡ŒçŸ©é™£ä¹˜æ³•
        start_event = torch.cuda.Event(enable_timing=True)
        end_event = torch.cuda.Event(enable_timing=True)
        
        start_event.record()
        z = torch.matmul(x, y)
        end_event.record()
        
        torch.cuda.synchronize()
        elapsed_time = start_event.elapsed_time(end_event)
        
        print(f"âœ… GPU é‹ç®—æˆåŠŸï¼")
        print(f"çŸ©é™£ä¹˜æ³• (1000x1000) è€—æ™‚: {elapsed_time:.2f} ms")
        
    except Exception as e:
        print(f"âŒ GPU é‹ç®—å¤±æ•—: {e}")
        
else:
    print("\nâŒ ç„¡æ³•åµæ¸¬åˆ° GPUï¼")
    print("\nå¯èƒ½çš„åŸå› ï¼š")
    print("1. PyTorch å®‰è£çš„æ˜¯ CPU ç‰ˆæœ¬")
    print("2. NVIDIA é©…å‹•æœªæ­£ç¢ºå®‰è£")
    print("3. CUDA ç‰ˆæœ¬ä¸ç›¸å®¹")
    
    # æª¢æŸ¥ç³»çµ± NVIDIA é©…å‹•
    print("\nğŸ” æª¢æŸ¥ NVIDIA é©…å‹•...")
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIA é©…å‹•å·²å®‰è£")
            # é¡¯ç¤ºç°¡çŸ­çš„ nvidia-smi è¼¸å‡º
            lines = result.stdout.split('\n')
            for line in lines[:7]:  # åªé¡¯ç¤ºå‰å¹¾è¡Œ
                print(line)
        else:
            print("âŒ ç„¡æ³•åŸ·è¡Œ nvidia-smiï¼Œè«‹ç¢ºèª NVIDIA é©…å‹•æ˜¯å¦å®‰è£")
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° nvidia-smi æŒ‡ä»¤ï¼Œè«‹ç¢ºèª NVIDIA é©…å‹•æ˜¯å¦å®‰è£")
    
    # æä¾›è§£æ±ºæ–¹æ¡ˆ
    print("\nğŸ’¡ è§£æ±ºæ–¹æ¡ˆï¼š")
    print("\n1. å¦‚æœ nvidia-smi æ­£å¸¸ä½† PyTorch ç„¡æ³•åµæ¸¬ GPUï¼Œè«‹é‡æ–°å®‰è£ PyTorch GPU ç‰ˆæœ¬ï¼š")
    print("   pip uninstall torch torchvision torchaudio")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    
    print("\n2. å¦‚æœä½¿ç”¨ condaï¼Œè«‹ä½¿ç”¨ï¼š")
    print("   conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia")
    
    print("\n3. æª¢æŸ¥æ‚¨çš„ CUDA ç‰ˆæœ¬æ˜¯å¦èˆ‡ PyTorch ç›¸å®¹")

# 4. é¡¯ç¤ºå»ºè­°çš„å®‰è£æŒ‡ä»¤
print("\n" + "=" * 60)
print("ğŸ“Œ æ ¹æ“šæ‚¨çš„ç’°å¢ƒï¼Œå»ºè­°ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤å®‰è£ PyTorchï¼š")

if sys.platform.startswith('win'):
    print("\nWindows ç³»çµ±ï¼š")
    print("# CUDA 11.8")
    print("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    print("\n# CUDA 12.1")
    print("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
else:
    print("\nLinux/Mac ç³»çµ±ï¼š")
    print("# CUDA 11.8")
    print("pip install torch torchvision torchaudio")

print("\n" + "=" * 60)

# 5. ç’°å¢ƒè®Šæ•¸æª¢æŸ¥
print("\nğŸ” ç’°å¢ƒè®Šæ•¸æª¢æŸ¥ï¼š")
import os
cuda_home = os.environ.get('CUDA_HOME') or os.environ.get('CUDA_PATH')
if cuda_home:
    print(f"CUDA_HOME/CUDA_PATH: {cuda_home}")
else:
    print("âš ï¸ CUDA_HOME æˆ– CUDA_PATH ç’°å¢ƒè®Šæ•¸æœªè¨­å®š")

path = os.environ.get('PATH', '')
if 'cuda' in path.lower():
    print("âœ… PATH åŒ…å« CUDA è·¯å¾‘")
else:
    print("âš ï¸ PATH å¯èƒ½æœªåŒ…å« CUDA è·¯å¾‘")

print("\n" + "=" * 60)
print("è¨ºæ–·å®Œæˆï¼")